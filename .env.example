# RunPod GPT-OSS-20B Worker Environment Variables
# Copy this to .env and modify as needed

# Model Configuration
MODEL_NAME=openai/gpt-oss-20b
MAX_MODEL_LEN=32768
GPU_MEMORY_UTILIZATION=0.95
MAX_NUM_SEQS=256
TENSOR_PARALLEL_SIZE=1
DTYPE=auto
TRUST_REMOTE_CODE=true

# Performance Settings
ENABLE_CHUNKED_PREFILL=true
MAX_CONCURRENCY=300
DISABLE_LOG_STATS=false

# HuggingFace Token (optional - if model is gated)
# HF_TOKEN=hf_xxxxxxxxxxxxxxxxxxxxx

# RunPod API Key (for local testing)
# RUNPOD_API_KEY=xxxxxxxxxxxxxxxxxxxxx

# VLLM Settings
VLLM_USE_FLASHINFER_SAMPLER=0

# Cache directories (for RunPod network volume)
HF_HOME=/runpod-volume/huggingface
TRANSFORMERS_CACHE=/runpod-volume/huggingface

